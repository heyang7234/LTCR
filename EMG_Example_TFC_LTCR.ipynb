{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:01.905296300Z",
     "start_time": "2023-11-09T02:35:01.403052900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:01.920926500Z",
     "start_time": "2023-11-09T02:35:01.654602Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from EMG_TFC_LTCR import COMET\n",
    "from models.encoder import FTClassifier\n",
    "# import datautils\n",
    "\n",
    "\n",
    "from tasks.fine_tuning_UCR_not_balance import finetune_fit\n",
    "from tasks.fine_tuning_UCR_not_balance import finetune_predict\n",
    "from tasks.fine_tuning_UCR_not_balance import finetune_predict\n",
    "from tasks.linear_evaluation_UCR_not_balance import eval_classification\n",
    "# from dataloading.ad_preprocessing import load_ad\n",
    "from config_files.EMG_Configs_my import Config as Configs\n",
    "from dct_func import FFT_for_Period\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import sklearn\n",
    "from utils_cpc import plot_channels #\n",
    "from utils_cpc import process_batch_ts\n",
    "from utils_cpc import split_data_label\n",
    "from utils_cpc import start_logging\n",
    "from utils_cpc import stop_logging\n",
    "from utils_cpc import seed_everything\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:02.102295400Z",
     "start_time": "2023-11-09T02:35:01.842412500Z"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1676328072870,
     "user": {
      "displayName": "Lucian",
      "userId": "17113640720459928730"
     },
     "user_tz": 300
    },
    "id": "T5Qnm0ILMZJQ"
   },
   "outputs": [],
   "source": [
    "configs = Configs()\n",
    "RANDOM_SEED = configs.RANDOM_SEED\n",
    "\n",
    "# Autoload the modified python file\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Specify saving and logging directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:02.278596700Z",
     "start_time": "2023-11-09T02:35:02.067331100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "working_directory = configs.working_directory\n",
    "dataset_save_path = working_directory\n",
    "if not os.path.exists(working_directory):\n",
    "    os.makedirs(working_directory)\n",
    "\n",
    "logging_directory = configs.logging_directory\n",
    "if not os.path.exists(logging_directory):\n",
    "    os.makedirs(logging_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Load and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from TSC_dataloader import TSC_multivariate_data_loader, TSC_data_loader_ts\n",
    "from OS_CNN_utils.dataloader.TSC_data_loader import TSC_multivariate_data_loader,TSC_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasetPath = \"datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = \"NerveDamage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train, y_train, X_test, y_test = TSC_data_loader(datasetPath, dataset)\n",
    "# X_train = X_train.reshape(X_train.shape[0],1,-1)\n",
    "# X_test = X_test.reshape(X_test.shape[0],1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = TSC_multivariate_data_loader(datasetPath, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def split_ucr(X_train, X_test, y_train, y_test,ratio = 0.2):\n",
    "\n",
    "\n",
    "    # 存储文件名\n",
    "    filenames = []\n",
    "    train_len = int(X_train.shape[0] * (1-ratio))\n",
    "    val_len = X_train.shape[0] - train_len\n",
    "    # reshape and shuffle\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "    X_val = X_train[train_len:]\n",
    "    y_val = y_train[train_len:]\n",
    "    X_train = X_train[:train_len]\n",
    "    y_train = y_train[:train_len]\n",
    "    # print(y_val.shape)\n",
    "\n",
    "    user_train = np.ones((y_train.shape[0], 1))\n",
    "    user_val = np.ones((y_val.shape[0], 1))\n",
    "    user_test = np.ones((y_test.shape[0], 1))\n",
    "    # print(y_val.shape)\n",
    "    # print(user_val.shape,y_val.reshape(y_val.shape[0],1).shape)\n",
    "    y_train = np.hstack((y_train.reshape(y_train.shape[0],1), user_train))\n",
    "    y_val = np.hstack((y_val.reshape(y_val.shape[0],1), user_val))\n",
    "    y_test = np.hstack((y_test.reshape(y_test.shape[0],1), user_test))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[2], X_train.shape[1])\n",
    "# X_test = X_test.reshape(205, 18530, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[2], X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodicity, freq_list = FFT_for_Period(torch.tensor(X_train), 500) # \n",
    "periodicity = torch.from_numpy(np.array([periodicity]))\n",
    "# periodicity = periodicity.item()\n",
    "periodicity\n",
    "# tensor([[1280,  640,  426,  320,  256,  213,  182,  160]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels(1, X_train[1][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels(1, X_train[2][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels(1, X_train[3][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_ucr(X_train, X_test, y_train, y_test,ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:03.036742900Z",
     "start_time": "2023-11-09T02:35:02.278596700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6758,
     "status": "ok",
     "timestamp": 1676328080495,
     "user": {
      "displayName": "Lucian",
      "userId": "17113640720459928730"
     },
     "user_tz": 300
    },
    "id": "SFlMhpSe5IWB",
    "outputId": "c395125c-ce87-4d3d-a1da-e771028212b3"
   },
   "outputs": [],
   "source": [
    "# data_path = \"datasets/AbnormalHeartbeat/Feature/\"\n",
    "# label_path = \"datasets/AbnormalHeartbeat/label.npy\"\n",
    "# val_ids = [17,18]  # specify patient ID for validation and test set\n",
    "# test_ids = [19,20]\n",
    "# X_trial_train, X_trial_val, X_trial_test, y_trial_train, y_trial_val, y_trial_test = load_ad(val_ids, test_ids, data_path, label_path)\n",
    "# print(X_trial_train.shape)\n",
    "# print(y_trial_train.shape)\n",
    "# print(X_trial_val.shape)\n",
    "# print(y_trial_val.shape)\n",
    "# print(X_trial_test.shape)\n",
    "# print(y_trial_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:03.569229500Z",
     "start_time": "2023-11-09T02:35:02.862963700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X_trial_train = process_batch_ts(X_train, normalized=True, bandpass_filter=False)\n",
    "X_trial_val = process_batch_ts(X_val, normalized=True, bandpass_filter=False)\n",
    "X_trial_test = process_batch_ts(X_test, normalized=True, bandpass_filter=False)\n",
    "print(X_trial_train.shape)\n",
    "print(X_trial_val.shape)\n",
    "print(X_trial_test.shape)\n",
    "y_trial_train = y_train\n",
    "y_trial_val = y_val\n",
    "y_trial_test = y_test\n",
    "print(y_trial_train.shape)\n",
    "print(y_trial_val.shape)\n",
    "print(y_trial_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:03.969197400Z",
     "start_time": "2023-11-09T02:35:03.569229500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split trail-level data into sample-level data\n",
    "X_train, y_train = split_data_label(X_trial_train,y_trial_train, sample_timestamps=configs.S_TIMESTAMPS, overlapping=configs.S_OVERLAPPING)\n",
    "X_val, y_val = split_data_label(X_trial_val,y_trial_val, sample_timestamps=configs.S_TIMESTAMPS, overlapping=configs.S_OVERLAPPING)\n",
    "X_test, y_test = split_data_label(X_trial_test,y_trial_test, sample_timestamps=configs.S_TIMESTAMPS, overlapping=configs.S_OVERLAPPING)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_trial_train\n",
    "del X_trial_val\n",
    "del X_trial_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:04.375923800Z",
     "start_time": "2023-11-09T02:35:03.969197400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # plot first sample, first four channels\n",
    "# plot_channels(1, X_trial_train[0][:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "\n",
    "print(\"cuDNN available:\", torch.backends.cudnn.enabled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzsn8WX82O5c"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:04.569609300Z",
     "start_time": "2023-11-09T02:35:04.329058300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The program will run on {device}!\")\n",
    "# device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:04.758668200Z",
     "start_time": "2023-11-09T02:35:04.569609300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pretrain_callback(model, loss):\n",
    "    n = model.n_epochs\n",
    "    metrics_dict = {}\n",
    "    if n % 1 == 0:\n",
    "        metrics_dict = eval_classification(model, X_train, y_train[:, 0], X_val, y_val[:, 0], fraction=1)\n",
    "        print(metrics_dict)\n",
    "        model.save(f\"{working_directory}seed{RANDOM_SEED}_pretrain_model.pt\")\n",
    "    return metrics_dict['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:35:04.947506400Z",
     "start_time": "2023-11-09T02:35:04.758668200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def finetune_callback(model, f1, fraction=1.0):\n",
    "    n = model.n_epochs\n",
    "    if model.n_epochs == 1:\n",
    "        model.finetune_f1 = f1\n",
    "        torch.save(model.state_dict(), f\"{working_directory}seed{RANDOM_SEED}_max_f1_{fraction}_finetune_model.pt\")\n",
    "    # control the saving frequency\n",
    "    if n % 1 == 0:\n",
    "        if f1 > model.finetune_f1:\n",
    "            model.finetune_f1 = f1\n",
    "            torch.save(model.state_dict(), f\"{working_directory}seed{RANDOM_SEED}_max_f1_{fraction}_finetune_model.pt\")\n",
    "    return finetune_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Self-Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:36:10.310784300Z",
     "start_time": "2023-11-09T02:35:04.947506400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262193,
     "status": "ok",
     "timestamp": 1675656463615,
     "user": {
      "displayName": "Lucian",
      "userId": "17113640720459928730"
     },
     "user_tz": 300
    },
    "id": "27wjLpD237VR",
    "outputId": "cc4d88e7-1cfe-4bb5-d642-cbd3a879d335"
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "# Train a COMET model\n",
    "seed_everything(RANDOM_SEED)\n",
    "model = COMET(\n",
    "    input_dims=configs.input_dims,\n",
    "    device=device,\n",
    "    lr=configs.pretrain_lr,\n",
    "    depth=configs.depth,\n",
    "    batch_size=configs.pretrain_batch_size,\n",
    "    # batch_size=512, #simclr \n",
    "    output_dims=configs.output_dims,\n",
    "    flag_use_multi_gpu=configs.flag_use_multi_gpu,\n",
    "    after_epoch_callback=pretrain_callback,\n",
    ")\n",
    "\n",
    "epoch_loss_list, epoch_f1_list = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    shuffle_function = configs.shuffle_function,\n",
    "    verbose=configs.verbose,\n",
    "    n_epochs=configs.n_epochs,\n",
    "    masks = configs.masks,\n",
    "    factors = configs.factors\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(f'Duration: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Linear evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:36:12.384162700Z",
     "start_time": "2023-11-09T02:36:10.770265300Z"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1676328695263,
     "user": {
      "displayName": "Lucian",
      "userId": "17113640720459928730"
     },
     "user_tz": 300
    },
    "id": "1nZhs42So9i5"
   },
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "seed_everything(RANDOM_SEED)\n",
    "pretrain_model = COMET(\n",
    "    input_dims=configs.input_dims,\n",
    "    device=device,\n",
    "    lr=configs.pretrain_lr,\n",
    "    depth=configs.depth,\n",
    "    batch_size=configs.pretrain_batch_size,\n",
    "    output_dims=configs.output_dims,\n",
    "    flag_use_multi_gpu=configs.flag_use_multi_gpu,\n",
    "    after_epoch_callback=pretrain_callback,\n",
    ")\n",
    "\n",
    "pretrain_model.load(f\"{working_directory}seed{RANDOM_SEED}_pretrain_model.pt\")\n",
    "\n",
    "start_logging(RANDOM_SEED, logging_directory)\n",
    "val_metrics_dict = eval_classification(pretrain_model, X_train, y_train[:, 0], X_val, y_val[:, 0])\n",
    "print(\"Linear evaluation for validation set\\n\",val_metrics_dict)\n",
    "test_metrics_dict = eval_classification(pretrain_model, X_train, y_train[:, 0], X_test, y_test[:, 0])\n",
    "print(\"Linear evaluation for test set\\n\",test_metrics_dict)\n",
    "print()\n",
    "stop_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Full fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:36:12.619992800Z",
     "start_time": "2023-11-09T02:36:12.368890200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_SEED)\n",
    "finetune_model = FTClassifier(input_dims=configs.input_dims, output_dims=configs.output_dims, depth=configs.depth, p_output_dims=configs.num_classes, device=device, flag_use_multi_gpu=configs.flag_use_multi_gpu)\n",
    "finetune_model.net.load_state_dict(torch.load(f\"{working_directory}seed{RANDOM_SEED}_pretrain_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:38:31.621606700Z",
     "start_time": "2023-11-09T02:36:12.629009600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_SEED)\n",
    "epoch_loss_list, epoch_f1_list = finetune_fit(finetune_model, X_train, y_train[:, 0], X_val, y_val[:, 0], batch_size=configs.finetune_batch_size_100, finetune_epochs=configs.finetune_epochs_100, num_classes=configs.num_classes, finetune_lr=configs.finetune_lr_100, fraction=configs.fraction_100, device=device, callback=finetune_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:38:32.396519900Z",
     "start_time": "2023-11-09T02:38:31.621606700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune_model.load_state_dict(torch.load(f\"{working_directory}seed{RANDOM_SEED}_max_f1_{configs.fraction_100}_finetune_model.pt\"))\n",
    "start_logging(RANDOM_SEED, logging_directory)\n",
    "print(f\"Finetune for {configs.fraction_100} fraction of validation set\")\n",
    "finetune_predict(finetune_model, X_val, y_val[:,0],num_classes = configs.num_classes)\n",
    "print(f\"Finetune for {configs.fraction_100} fraction of test set\")\n",
    "finetune_predict(finetune_model, X_test, y_test[:,0],num_classes = configs.num_classes)\n",
    "print()\n",
    "stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:38:32.834496600Z",
     "start_time": "2023-11-09T02:38:32.396519900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_loss_list)\n",
    "plt.title('Loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_f1_list)\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Semi-supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 10% label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:38:33.163219500Z",
     "start_time": "2023-11-09T02:38:32.834496600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_SEED)\n",
    "finetune_model = FTClassifier(input_dims=configs.input_dims, output_dims=configs.output_dims, depth=configs.depth, p_output_dims=configs.num_classes, device=device, flag_use_multi_gpu=configs.flag_use_multi_gpu)\n",
    "finetune_model.net.load_state_dict(torch.load(f\"{working_directory}seed{RANDOM_SEED}_pretrain_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:10.549066700Z",
     "start_time": "2023-11-09T02:38:33.158459600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_SEED)\n",
    "epoch_loss_list, epoch_f1_list = finetune_fit(finetune_model, X_train, y_train[:, 0], X_val, y_val[:, 0], batch_size=configs.finetune_batch_size_10,finetune_epochs=configs.finetune_epochs_10, num_classes=configs.num_classes, finetune_lr=configs.finetune_lr_10, fraction=configs.fraction_10, device=device, callback=finetune_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:11.209845900Z",
     "start_time": "2023-11-09T02:39:10.549066700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune_model.load_state_dict(torch.load(f\"{working_directory}seed{RANDOM_SEED}_max_f1_{configs.fraction_10}_finetune_model.pt\"))\n",
    "start_logging(RANDOM_SEED, logging_directory)\n",
    "print(f\"Finetune for {configs.fraction_10} fraction of validation set\")\n",
    "finetune_predict(finetune_model, X_val, y_val[:,0],num_classes = configs.num_classes)\n",
    "print(f\"Finetune for {configs.fraction_10} fraction of test set\")\n",
    "finetune_predict(finetune_model, X_test, y_test[:,0],num_classes = configs.num_classes)\n",
    "print()\n",
    "stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:11.665719100Z",
     "start_time": "2023-11-09T02:39:11.209845900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_loss_list)\n",
    "plt.title('Loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_f1_list)\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1% label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:11.948221500Z",
     "start_time": "2023-11-09T02:39:11.665719100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_SEED)\n",
    "finetune_model = FTClassifier(input_dims=configs.input_dims, output_dims=configs.output_dims, depth=configs.depth, p_output_dims=configs.num_classes, device=device, flag_use_multi_gpu=configs.flag_use_multi_gpu)\n",
    "finetune_model.net.load_state_dict(torch.load(f\"{working_directory}seed{RANDOM_SEED}_pretrain_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:29.896383Z",
     "start_time": "2023-11-09T02:39:11.932603700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_SEED)\n",
    "epoch_loss_list, epoch_f1_list = finetune_fit(finetune_model, X_train, y_train[:, 0], X_val, y_val[:, 0], batch_size=configs.finetune_batch_size_1,finetune_epochs=configs.finetune_epochs_1, num_classes=configs.num_classes, finetune_lr=configs.finetune_lr_1, fraction=configs.fraction_1, device=device, callback=finetune_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:30.459776100Z",
     "start_time": "2023-11-09T02:39:29.896383Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune_model.load_state_dict(torch.load(f\"{working_directory}seed{RANDOM_SEED}_max_f1_{configs.fraction_1}_finetune_model.pt\"))\n",
    "start_logging(RANDOM_SEED, logging_directory)\n",
    "print(f\"Finetune for {configs.fraction_1} fraction of validation set\")\n",
    "finetune_predict(finetune_model, X_val, y_val[:,0],num_classes = configs.num_classes)\n",
    "print(f\"Finetune for {configs.fraction_1} fraction of test set\")\n",
    "finetune_predict(finetune_model, X_test, y_test[:,0],num_classes = configs.num_classes)\n",
    "print()\n",
    "stop_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:30.904193900Z",
     "start_time": "2023-11-09T02:39:30.459776100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_loss_list)\n",
    "plt.title('Loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_f1_list)\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:31.095064300Z",
     "start_time": "2023-11-09T02:39:30.872558700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print(f'Duration: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T02:39:31.108070700Z",
     "start_time": "2023-11-09T02:39:31.095064300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPJ0yeKiuGHJFdmAGX+ukV4",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
